{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9c0528-0e43-4065-920a-1311b7acfac8",
   "metadata": {},
   "source": [
    "# U-Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5094f6e-ade2-477a-a0eb-579e942286cf",
   "metadata": {},
   "source": [
    "## Import Libraries, Modules, & Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9154480-d306-475e-b55d-1d463e3d3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from unet import UNet\n",
    "from dataset import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c26e4-4415-4e85-8806-35aeec739777",
   "metadata": {},
   "source": [
    "## Set Hyperparameters and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f6a0f1-240d-43da-8cbb-28c6d081882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 3e-4\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 1\n",
    "DATA_PATH = '25-ds-casia-un-tvt'\n",
    "MODEL_SAVE_PATH = 'un-model/ds4-un-model.pth'\n",
    "RESUME_TRAINING = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a0671-aef2-47e4-84c6-7137e334bcfa",
   "metadata": {},
   "source": [
    "### Select Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b7e378d-9836-4cbe-a301-0a146a959adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d6c991-6f25-4472-acf7-5de8865d3c10",
   "metadata": {},
   "source": [
    "## Create Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bf6fdf-7afe-478a-b36d-a2ff68de68ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset(root_path=DATA_PATH, split='train')\n",
    "val_dataset = dataset(root_path=DATA_PATH, split='validation')\n",
    "test_dataset = dataset(root_path=DATA_PATH, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0229fdd3-41fa-48e2-ad3a-0c06ebbeb405",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d43118-8c5f-44b8-ae60-817cc9adad3c",
   "metadata": {},
   "source": [
    "## Initialize Model, Optimizer, and Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4c796-104f-4dc1-a1cb-4806d915c7fb",
   "metadata": {},
   "source": [
    "### Class Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f30e65-3c47-45df-905e-b33e0fa0274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_px = 0\n",
    "total_tp_px = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b9c949-4a7f-48c1-b621-8276e70647a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask in train_dataloader:\n",
    "    total_px += mask.nelement()\n",
    "    total_tp_px += mask.sum().item()\n",
    "\n",
    "# Calculate the ratio\n",
    "au_px = total_px - total_tp_px\n",
    "pos_weight = au_px / total_tp_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb76617-7cd1-4688-9753-3d07354fbcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pixels: 58851328\n",
      "Total tampered pixels: 6278448.774902344\n",
      "Calculated pos_weight: 8.373545936259612\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total pixels: {total_px}\")\n",
    "print(f\"Total tampered pixels: {total_tp_px}\")\n",
    "print(f\"Calculated pos_weight: {pos_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a745b8-5a42-44a9-ba3f-d06fbf155562",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight_tensor = torch.tensor([pos_weight]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af5a3f3c-417a-47f1-8b0b-f729720ca8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=3, num_classes=1).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496247c3-08bf-466d-b913-f4bfaaadb9ed",
   "metadata": {},
   "source": [
    "## If Resume Training, then Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0490b5c8-bba6-4ad5-94b2-8b9429913920",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESUME_TRAINING:\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "        print(\"Loaded model weights from checkpoint.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc3ccd4-1f0b-4400-b1bc-a7cec84fe216",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81cac11-e2c2-4f18-bd4d-05f4d9494d5d",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d95c6c4d-09ae-4da6-8d79-bcc29d6fc20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [09:30<00:00, 10.02s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:55<00:00,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "EPOCH 1\n",
      "Training Accuracy: 53.3512% | Training Loss: 1.2183\n",
      "Validation Accuracy: 63.8073% | Validation Loss: 1.0550\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_running_loss = 0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for idx, img_mask in enumerate(tqdm(train_dataloader)):\n",
    "        img = img_mask[0].float().to(device)\n",
    "        mask = img_mask[1].float().to(device)\n",
    "\n",
    "        y_pred = model(img)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(y_pred, mask)\n",
    "        train_running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy for binary segmentation\n",
    "        predicted = (torch.sigmoid(y_pred) > 0.5).float()\n",
    "        train_total += mask.nelement()\n",
    "        train_correct += (predicted == mask).sum().item()\n",
    "\n",
    "    train_loss = train_running_loss / (idx + 1)\n",
    "    train_accuracy = 100 * train_correct / train_total \n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, img_mask in enumerate(tqdm(val_dataloader)):\n",
    "            img = img_mask[0].float().to(device)\n",
    "            mask = img_mask[1].float().to(device)\n",
    "\n",
    "            y_pred = model(img)\n",
    "            loss = criterion(y_pred, mask)\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            # Calculate validation accuracy for binary segmentation\n",
    "            predicted = (torch.sigmoid(y_pred) > 0.5).float()\n",
    "            val_total += mask.nelement()\n",
    "            val_correct += (predicted == mask).sum().item()\n",
    "\n",
    "        val_loss = val_running_loss / (idx + 1)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"EPOCH {epoch + 1}\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}% | Training Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}% | Validation Loss: {val_loss:.4f}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b65ece-f77d-4844-bc55-783508298b28",
   "metadata": {},
   "source": [
    "### Training Loop Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc921d-cba1-4dc7-8deb-4dcc25fe1c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b976b37-fa4c-4129-8160-90b86ac03279",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4f93756-e921-47ce-90fe-d3bdaa7de535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to un-model/ds4-un-model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "print(f\"Model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3365afc4-f750-4e4a-98a0-2ae2387f9b46",
   "metadata": {},
   "source": [
    "## Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df61b39f-bc89-4068-bef1-b8e767a35116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/8 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(img)\n\u001b[0;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, mask)\n\u001b[1;32m---> 11\u001b[0m     test_running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m test_running_loss \u001b[38;5;241m/\u001b[39m (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_running_loss = 0\n",
    "with torch.no_grad():\n",
    "    for idx, img_mask in enumerate(tqdm(test_dataloader)):\n",
    "        img = img_mask[0].float().to(device)\n",
    "        mask = img_mask[1].float().to(device)\n",
    "\n",
    "        y_pred = model(img)\n",
    "        loss = criterion(y_pred, mask)\n",
    "\n",
    "        test_running_loss += loss.item()\n",
    "\n",
    "    test_loss = test_running_loss / (idx + 1)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce6867a-a2cb-450d-9758-c8d4a81e719c",
   "metadata": {},
   "source": [
    "### Test Loop Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e22395-783d-4b30-8894-5300aaa61cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
