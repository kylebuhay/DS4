{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9c0528-0e43-4065-920a-1311b7acfac8",
   "metadata": {},
   "source": [
    "# U-Net Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03115ab5-f40e-4aab-a448-fe1f21bc7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study torchvision.transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f5c33-9713-40a4-9753-91183908363a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda90aa6-d781-4efe-b154-d99ce0b31dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504ff0f-1cd3-4db7-aa62-2460e88d531f",
   "metadata": {},
   "source": [
    "### Check for PyTorch GPU Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11faf8d6-4b65-4cae-9343-f17c6ce8f7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20ef863-d195-4908-9b3f-8b7b6c83509f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Preprocessing (Tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9748638-3506-41e1-802a-8c7de4307867",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ae4f32-3a70-4076-bc2e-0d42e5940f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds25_tp_ts = '25-ds-casia-un-tvt/train/train_tp'\n",
    "sds25_tp_vs = '25-ds-casia-un-tvt/validation/validation_tp'\n",
    "sds25_tp_testset = '25-ds-casia-un-tvt/test/test_tp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1494d5-531c-4f46-99fa-8286c42bac12",
   "metadata": {},
   "source": [
    "### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061247d5-ab04-4dcd-8ce5-6f149a08300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_tp(path):\n",
    "    supported_formats = ('.jpg', '.tif')\n",
    "    count_pp = 0\n",
    "\n",
    "    # Transformation to convert image to tensor and normalize to [0, 1]\n",
    "    transform = transforms.ToTensor()\n",
    "    \n",
    "    # Iterate over files in the specified directory\n",
    "    for filename in tqdm(os.listdir(path), desc=\"Preprocessing images\"):\n",
    "        if filename.lower().endswith(supported_formats):\n",
    "            # Full path to the image file\n",
    "            file_path = os.path.join(path, filename)\n",
    "            \n",
    "            # Open the image file using PIL\n",
    "            with Image.open(file_path) as img:\n",
    "                # Step 1: Resize image to 256x256\n",
    "                img = img.convert('RGB')\n",
    "                img = img.resize((256, 256), Image.LANCZOS)\n",
    "                \n",
    "                # Step 2: Convert image to numpy array\n",
    "                img_np = np.array(img, dtype=np.float32)\n",
    "                \n",
    "                # Step 3: Apply CLAHE\n",
    "                img_lab = cv2.cvtColor(img_np.astype(np.uint8), cv2.COLOR_RGB2LAB)\n",
    "                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "                img_lab[:, :, 0] = clahe.apply(img_lab[:, :, 0])\n",
    "                img_clahe = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "                \n",
    "                # Convert CLAHE result back to PIL image for torchvision transform\n",
    "                img_clahe_pil = Image.fromarray(img_clahe)\n",
    "                \n",
    "                # Step 4: Normalize pixel values to [0, 1] using torchvision transform\n",
    "                norm_img_tensor = transform(img_clahe_pil)\n",
    "\n",
    "                # Save the preprocessed image in a consistent format\n",
    "                img_clahe_pil.save(file_path, format='JPEG')\n",
    "                \n",
    "                count_pp += 1\n",
    "    \n",
    "    print(f\"Preprocessed {count_pp} images in {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880005ca-891c-4ec1-9924-71110cb8c1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing images: 100%|██████████████████████████████████████████████████████████| 898/898 [00:09<00:00, 94.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 898 images in 25-ds-casia-un-tvt/train/train_tp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pp_tp(sds25_tp_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0f6447-636d-4e93-a3d5-199122983a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing images: 100%|██████████████████████████████████████████████████████████| 257/257 [00:02<00:00, 94.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 257 images in 25-ds-casia-un-tvt/validation/validation_tp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pp_tp(sds25_tp_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49aa34c-cd8f-437e-bb5c-1938df0611e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing images: 100%|██████████████████████████████████████████████████████████| 126/126 [00:01<00:00, 92.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 126 images in 25-ds-casia-un-tvt/test/test_tp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pp_tp(sds25_tp_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f3e16-0587-4bf1-ad77-501abdf4c7fe",
   "metadata": {},
   "source": [
    "### Verifying Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ae38012-4f39-4721-b69e-9e1b4e77f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vf_pp_pxvalues(path):\n",
    "    # Supported image formats\n",
    "    image_extensions = ['.jpg', '.tif', '.png']\n",
    "    \n",
    "    # Initialize variables\n",
    "    count_img = 0\n",
    "    px_min = float('inf')\n",
    "    px_max = float('-inf')\n",
    "\n",
    "    # Transformation to convert image to tensor and normalize to [0, 1]\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # Iterate through files in the directory\n",
    "    for filename in os.listdir(path):\n",
    "        file_extension = os.path.splitext(filename)[1].lower()\n",
    "        if file_extension in image_extensions:\n",
    "            image_path = os.path.join(path, filename)\n",
    "            \n",
    "            # Read image using PIL\n",
    "            with Image.open(image_path) as img:\n",
    "                # Convert to tensor and normalize\n",
    "                img_tensor = transform(img)\n",
    "                min_val = img_tensor.min().item()\n",
    "                max_val = img_tensor.max().item()\n",
    "                \n",
    "                if min_val < px_min:\n",
    "                    px_min = min_val\n",
    "                if max_val > px_max:\n",
    "                    px_max = max_val\n",
    "\n",
    "                count_img += 1\n",
    "    \n",
    "     # Print the result\n",
    "    if count_img > 0:\n",
    "        print(f\"Read {count_img} images.\\nThe pixel values for the images are in the range {px_min} - {px_max}.\")\n",
    "    else:\n",
    "        print(\"No images found in the specified path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d87dc2-bc9c-4df8-902d-1d500d7f3f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 898 images.\n",
      "The pixel values for the images are in the range 0.0 - 1.0.\n"
     ]
    }
   ],
   "source": [
    "vf_pp_pxvalues(sds25_tp_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "306c9b75-eef3-40b6-a311-b9324c725870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 257 images.\n",
      "The pixel values for the images are in the range 0.0 - 1.0.\n"
     ]
    }
   ],
   "source": [
    "vf_pp_pxvalues(sds25_tp_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76b6fcc4-15a7-4653-8d15-1826f72c43a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 126 images.\n",
      "The pixel values for the images are in the range 0.0 - 1.0.\n"
     ]
    }
   ],
   "source": [
    "vf_pp_pxvalues(sds25_tp_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd60d136-2133-423a-8a56-01c47d28c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vf_pp_shape(path):\n",
    "    unique_shapes = set()\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".tif\") or filename.endswith(\".png\"):\n",
    "            filepath = os.path.join(path, filename)\n",
    "            # Open the image\n",
    "            image = Image.open(filepath)\n",
    "            # Convert the image to a numpy array to get its shape\n",
    "            image_array = np.array(image)\n",
    "            # Get the shape of the image\n",
    "            shape = image_array.shape\n",
    "            unique_shapes.add(shape)\n",
    "    \n",
    "    print(f\"Image Shape/s from {path}\")\n",
    "    for shape in unique_shapes:\n",
    "        print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "127ccfad-4c9b-4b9d-9b66-9f11bd1db827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape/s from 25-ds-casia-un-tvt/train/train_tp\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "vf_pp_shape(sds25_tp_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b36554d5-0851-44c3-aee1-51b88cb7d9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape/s from 25-ds-casia-un-tvt/validation/validation_tp\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "vf_pp_shape(sds25_tp_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94ac9e5c-6773-441f-88cd-3b92deae4f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape/s from 25-ds-casia-un-tvt/test/test_tp\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "vf_pp_shape(sds25_tp_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f39390-84c9-4e66-942f-06437bf1a113",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Preprocessing (Gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828440a7-58e0-40da-b2a7-13bf3c20f235",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10d7fe65-65e4-480b-943a-99f89a2f2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds25_gt_ts = '25-ds-casia-un-tvt/train/train_gt'\n",
    "sds25_gt_vs = '25-ds-casia-un-tvt/validation/validation_gt'\n",
    "sds25_gt_testset = '25-ds-casia-un-tvt/test/test_gt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae00cc-30d4-45a8-9517-721192aecdbb",
   "metadata": {},
   "source": [
    "### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0b66792-9327-4a9a-a698-8247cbecf58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_gt(path):\n",
    "    supported_formats = ('.png')\n",
    "    count_pp = 0\n",
    "\n",
    "    # Transformation to convert image to tensor\n",
    "    transform = transforms.ToTensor()\n",
    "    \n",
    "    # Iterate over files in the specified directory\n",
    "    for filename in tqdm(os.listdir(path), desc=\"Preprocessing images\"):\n",
    "        if filename.lower().endswith(supported_formats):\n",
    "            # Full path to the image file\n",
    "            file_path = os.path.join(path, filename)\n",
    "            \n",
    "            # Open the image file using PIL\n",
    "            with Image.open(file_path) as img:\n",
    "                # Step 1: Convert to grayscale (single-channel) and resize image to 256x256\n",
    "                img = img.convert('L')\n",
    "                img = img.resize((256, 256), Image.NEAREST)\n",
    "                \n",
    "                # Step 2: Convert image to numpy array\n",
    "                img_np = np.array(img, dtype=np.uint8)\n",
    "                \n",
    "                # Step 3: Normalize pixel values to [0, 1] using torchvision transform\n",
    "                norm_img_tensor = transform(img_np)\n",
    "                \n",
    "                # Convert tensor back to PIL image\n",
    "                norm_img_pil = transforms.ToPILImage()(norm_img_tensor)\n",
    "                \n",
    "                # Save the preprocessed image in a consistent format\n",
    "                norm_img_pil.save(file_path, format='PNG')\n",
    "                \n",
    "                count_pp += 1\n",
    "    \n",
    "    print(f\"Preprocessed {count_pp} images in {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fe12f0a-3689-49f3-b508-57f73d6b8534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing images: 100%|█████████████████████████████████████████████████████████| 898/898 [00:06<00:00, 146.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 898 images in 25-ds-casia-un-tvt/train/train_gt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pp_gt(sds25_gt_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b9ff17e-7fc7-420d-994e-4e5a3231da4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing images: 100%|█████████████████████████████████████████████████████████| 257/257 [00:01<00:00, 147.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 257 images in 25-ds-casia-un-tvt/validation/validation_gt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pp_gt(sds25_gt_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "203b22b4-c9b6-4876-93d9-0dbf0ebefbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing images: 100%|█████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 142.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 126 images in 25-ds-casia-un-tvt/test/test_gt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pp_gt(sds25_gt_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb46b071-c72c-4c2a-b388-5aa5f971c689",
   "metadata": {},
   "source": [
    "### Verifying Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01bd4d21-615c-4948-a1ff-29e452bd0488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 898 images.\n",
      "The pixel values for the images are in the range 0.0 - 1.0.\n"
     ]
    }
   ],
   "source": [
    "vf_pp_pxvalues(sds25_gt_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72db72f6-54a0-45a8-ab8d-45da88580e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 257 images.\n",
      "The pixel values for the images are in the range 0.0 - 1.0.\n"
     ]
    }
   ],
   "source": [
    "vf_pp_pxvalues(sds25_gt_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e38d1950-bf27-4f50-bf86-95218142cd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 126 images.\n",
      "The pixel values for the images are in the range 0.0 - 1.0.\n"
     ]
    }
   ],
   "source": [
    "vf_pp_pxvalues(sds25_gt_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a791268-da88-4910-9c4b-329761427e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape/s from 25-ds-casia-un-tvt/train/train_gt\n",
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "vf_pp_shape(sds25_gt_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4495afe-9c0e-4835-b79d-7151850de8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape/s from 25-ds-casia-un-tvt/validation/validation_gt\n",
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "vf_pp_shape(sds25_gt_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c4ec82d-d88e-4600-9553-f8957d03a3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape/s from 25-ds-casia-un-tvt/test/test_gt\n",
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "vf_pp_shape(sds25_gt_testset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
